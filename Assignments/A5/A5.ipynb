{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will be instructed to apply ** unsupervised ** learning to address a practical problem. For simplicity, we will use intrusion detection as an example. But the principle can be used in many other fields, such as fraud detection and medical care. After completing this assignment, you should be able to answer the following questions:\n",
    "\n",
    "1. How to standardize numerical features?\n",
    "2. How to transform categorical features into numerical features?\n",
    "3. How to derive anomalies from clustering results?\n",
    "4. How to tune parameters for unsupervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be downloaded from [A5-data.zip](A5-data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, when you are facing an ML problem, the process of solving it basically consists of two phases: _model development_ and _model serving_. \n",
    "\n",
    "* In model development, your job is to figure out what's the best algorithms, features, and parameters should be chosen based on historical data. This is often an iterative and off-line process. \n",
    "\n",
    "* Once you develop a satisfactory model, you will need to use the model to serve new requests and make predictions. This is often an on-line process, so you have to think about how to make the predictions as fast as possible and how to efficiently update the model when new data arrive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to focus on the model development stage. Model serving is also a very important topic. I hope you can learn it by yourself or through your final project. Below are a few good references: \n",
    "* [Deploy a Model in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html)\n",
    "* [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)\n",
    "* [Deploy models with Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where)\n",
    "* [Serving of ML models in Kubeflow](https://www.kubeflow.org/docs/components/serving/tfserving_new/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to develop a model that can detect anomalous connections to your company's server. The server log contains all the information of historical connections; your nice colleague has already helped you to transform the raw log into a collection of feature vectors, where each feature vector characterizes a connection in 40 dimensions, e.g., number of failed login attempts, length (number of seconds) of the connection. Here is one example feature vector:\n",
    "```\n",
    "[udp,SF,0,105,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,240,0.94,0.01,0.00,0.00,0.00,0.00,0.00,0.00]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to take these feature vectors as input and develop an unsupervised-learning model to detect anomalous connections. In the lecture, we have gone through this process. In the assignment, you are going to implement three functions: `cat2Num`, `scaleNum`, and `detect`, by doing Tasks A-C, respectively.\n",
    "\n",
    "``` python\n",
    "# anomaly_detection.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class AnomalyDetection():\n",
    "    \n",
    "    def scaleNum(self, df, indices):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    def cat2Num(self, df, indices):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "            \n",
    "\n",
    "    def detect(self, df, k, t):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('logs-features-sample.csv').set_index('id')\n",
    "    ad = AnomalyDetection()\n",
    "    \n",
    "    df1 = ad.cat2Num(df, [0,1])\n",
    "    print(df1)\n",
    "\n",
    "    df2 = ad.scaleNum(df1, [6])\n",
    "    print(df2)\n",
    "\n",
    "    df3 = ad.detect(df2, 8, 0.97)\n",
    "    print(df3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy dataset for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your program, you can read a toy dataset:\n",
    "\n",
    "```python\n",
    "    data = [(0, [\"http\", \"udt\", 4]), \\\n",
    "            (1, [\"http\", \"udf\", 5]), \\\n",
    "            (2, [\"http\", \"tcp\", 5]), \\\n",
    "            (3, [\"ftp\", \"icmp\", 1]), \\\n",
    "            (4, [\"http\", \"tcp\", 4])]\n",
    "\n",
    "    df = pd.DataFrame(data=data, columns = [\"id\", \"features\"])\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the script, your program should output the followings:\n",
    "\n",
    "**df1 = ad.cat2Num(df, [0,1])**\n",
    "\n",
    "```\n",
    "+---+---------------------+\n",
    "|id |features             |\n",
    "+---+---------------------+\n",
    "|0  |[1, 0, 1, 0, 0, 0, 4]|\n",
    "|1  |[1, 0, 0, 1, 0, 0, 5]|\n",
    "|2  |[1, 0, 0, 0, 1, 0, 5]|\n",
    "|3  |[0, 1, 0, 0, 0, 1, 1]|\n",
    "|4  |[1, 0, 0, 0, 1, 0, 4]|\n",
    "+---+---------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df2 = ad.scaleNum(df1, [6]):**\n",
    "\n",
    "```\n",
    "+---+---------------------------------------+\n",
    "|id |features                               |\n",
    "+---+---------------------------------------+\n",
    "|0  |[1, 0, 1, 0, 0, 0, 0.12171612389003701]|\n",
    "|1  |[1, 0, 0, 1, 0, 0, 0.7302967433402214] |\n",
    "|2  |[1, 0, 0, 0, 1, 0, 0.7302967433402214] |\n",
    "|3  |[0, 1, 0, 0, 0, 1, -1.704025734460517] |\n",
    "|4  |[1, 0, 0, 0, 1, 0, 0.12171612389003701]|\n",
    "+---+---------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** df3 = ad.detect(df2, 2, 0.9)**\n",
    "\n",
    "```\n",
    "+---+---------------------------------------+-----+\n",
    "|id |features                               |score|\n",
    "+---+---------------------------------------+-----+\n",
    "|3  |[0, 1, 0, 0, 0, 1, -1.704025734460517] |1.0  |\n",
    "+---+----------------+----------------------+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A. Categorical Features --> Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above feature vector, the first two dimensions in each feature vector are categorical features. For example, the first dimension can be one of the following cases: “http” or “ftp”. You can represent these categorical features using one-hot encoding, e.g., [1,0] for “http” and [0,1] for “ftp”. \n",
    "\n",
    "In Task A, your job is to implement the `cat2Num` function.\n",
    "\n",
    "```python\n",
    "    def cat2Num(self, df, indices):\n",
    "        \"\"\" \n",
    "            Input: $df represents a DataFrame with two columns: \"id\" and \"features\"\n",
    "                   $indices represents which dimensions in $features are categorical features, \n",
    "                    e.g., indices = [0, 1] denotes that the first two dimensions are categorical features.\n",
    "                    \n",
    "            Output: Return a new DataFrame that updates the \"features\" column with one-hot encoding. \n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You have to implement one-hot encoding by yourself rather than use an existing implmentation in a libary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B. Standardize Numerical Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means utilizes the distance between every two points to do clustering. We don't want the distance to be dominated by some features. To avoid this, we standardize those features that are on a larger scale. \n",
    "\n",
    "In Task B, your job is to implement the `scaleNum` function, which standardizes specified features by removing the mean and scaling to unit variance.\n",
    "\n",
    "\n",
    "```python\n",
    "    def scaleNum(self, df, indices):\n",
    "        \"\"\" \n",
    "            Input: $df represents a DataFrame with two columns: \"id\" and \"features\"\n",
    "                   $indices represents which dimensions in $features that need to be standardized\n",
    "                    \n",
    "            Output: Return a new DataFrame that updates \"features\" column with specified features standarized.\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "```\n",
    "\n",
    "**Note:** You have to implement StandardScaler by yourself rather than use an existing implmentation in a libary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C. Detect Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may remember, the intuition of our anomaly detection approach was that clusters with a small number of data points will correspond to attacks or anomalies. We use this intuition to generate a confidence score from the clustering model’s output. The confidence score reflects how much the clustering model believes a data point is an attack or not. Let us assume $x$ is a data point describing a network connection. We can use:\n",
    "\n",
    "$$score(x) = \\frac{N_{max}-N_{x}}{N_{max}-N_{min}}$$\n",
    "\n",
    "to score $x$ as being an anomaly. Note that in this equation, $N_{max}$ and $N_{min}$ reflect the size of the largest and smallest clusters, respectively. $N_{x}$ represents the size of the cluster assigned to $x$. If you check the equation carefully, you will notice that $score(x) = 1$ when $x$ is assigned to the smallest cluster and $score(x)$ = 0 when $x$ is assigned to a large cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Task C, your job is to implement the `detect` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def detect(self, df, k, t):\n",
    "    \"\"\" \n",
    "        Input: $df represents a DataFrame with two columns: \"id\" and \"features\"\n",
    "               $k is the number of clusters for K-Means\n",
    "               $t is the score threshold\n",
    "        \n",
    "        Output: Return a new DataFrame that adds the \"score\" column into the input $df and then\n",
    "                removes the rows whose scores are smaller than $t.  \n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning plays an essential role in improving model quality. In this assignment, your task is to figure out how to tune hyperparameters for **unsupervised learning**. There are two parameters that need to be tuned: \n",
    "\n",
    "* $k$: the number of clusters\n",
    "* $t$: the score threshold \n",
    "\n",
    "They are set to k = 8 and t = 0.97 in the above program. In fact, if you changed them to different values, the result could be quite different. Thus, it is important to know how to tune $k$ and $t$ in practice.  \n",
    "\n",
    "In Task D, imagine you are a data science manager. Please write an email (< 500 words) to tell a junior data scientist (named Nick) how to use [Bayesian Optimization](http://krasserm.github.io/2018/03/21/bayesian-optimization/) to tune the parameters. Your email needs to explain to Nick i) how bayesian optimization works in an intuitive way, and ii) why bayesian optimization could perform better than grid search and random search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `cat2Num`, `scaleNum`, and `detect` functions in `anomaly_detection.py`. Submit your code file (`anomaly_detection.py`), and your email content (`email.pdf`) to CourSys."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
